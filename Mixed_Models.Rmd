---
title: "Mixed Models"
author: "Pedro Victor Brasil Ribeiro"
date: "2021-11-22 - Last changed in `r Sys.Date()`"
header-includes:
   - \usepackage{amsmath}
   - \usepackage{bm}
   - \usepackage{multirow}
   - \usepackage{float}
output: pdf_document
---

```{r setup, include=FALSE}
library(usethis)
library(tidyverse)
library(bbmle)
library(magrittr)
library(lme4)
library(nlme)
library(kableExtra)
dados <- read_table2("https://raw.githubusercontent.com/ranalytics/r-tutorials/master/Edition_2015/Data/RIKZ.txt")
#load("C:/Users/Pedro/Desktop/Pedro/Github/Estatistica/Mixed_Models/lme_env.RData")
knitr::opts_chunk$set(echo = FALSE)
```

# Longitudinal Data

Longitudinal data, also called as panel data, is data that is collected through a series of repeated observations of the same subject overtime. Longitudinal experiments planning concern the observation of one or more variables in the same subject on different ocassions or condicion of evaluation, time is a commom factor used in most of experiment, but it can be use on distances among other factors, but in the present work it will be implied that the subjects measures is taken over time.

Given that longitudinal data are measures of the same subject taken in a systematic way, is expected not null correlations between the measures, especially the one taken in consecutive. Furthermore is expected heterocedasticidy.

About the data structure is expected 3 characteristics, but have in mind that in a real experiement ambient, not necessarily those characteristics can actually be hold:

\begin{itemize}
  \item Regular (in respect to time): The interval of time between one measure and other are the same;
  \item Balanced (in respect to time): All observations are taken in the same time, on the same condictions in all subjects;
  \item Complete: No lost observations.
\end{itemize}

\begin{table}[H]
\centering
\caption{Basic structure of balanced and complete longitudinal data}
\label{tab1}
\begin{tabular}{cccccc}
\hline
\multirow{2}{*}{Grupo ou Tratamento} & \multirow{2}{*}{Unidade Experimental} & \multicolumn{4}{c}{Condições de Avaliação} \\ \cline{3-6} 
                   &           &  1           & 2           & $\cdots$  & t           \\ \hline
\multirow{4}{*}{1} &  1        &  $y_{111}$   & $y_{112}$   & $\cdots$  & $y_{11t}$   \\
                   &  2        &  $y_{121}$   & $y_{122}$   & $\cdots$  & $y_{12t}$   \\
                   &  $\vdots$ &  $\vdots$    & $\vdots$    & $\ddots$  & $\vdots$    \\
                   &  $n_1$    &  $y_{1n_11}$ & $y_{1n_12}$ & $\cdots$  & $y_{1n_1t}$ \\ \hline
\multirow{4}{*}{2} &  1        &  $y_{211}$   & $y_{212}$   & $\cdots$  & $y_{21t}$   \\
                   &  2        &  $y_{221}$   & $y_{222}$   & $\cdots$  & $y_{22t}$   \\
                   &  $\vdots$ &  $\vdots$    & $\vdots$    & $\ddots$  & $\vdots$    \\
                   &  $n_2$    &  $y_{2n_21}$ & $y_{2n_22}$ & $\cdots$  & $y_{2n_2t}$ \\ \hline
$\vdots$           &  $\vdots$ &  $\vdots$    & $\vdots$    & $\vdots$  & $\vdots$    \\ \hline
\multirow{4}{*}{g} &  1        &  $y_{g11}$   & $y_{g12}$   & $\cdots$  & $y_{g1t}$   \\
                   &  2        &  $y_{g21}$   & $y_{g22}$   & $\cdots$  & $y_{g2t}$   \\
                   &  $\vdots$ &  $\vdots$    & $\vdots$    & $\vdots$  & $\vdots$    \\
                   &  $n_g$    &  $y_{gn_g1}$ & $y_{gn_g2}$ & $\cdots$  & $y_{gn_gt}$ \\ \hline
\end{tabular}
\end{table}

# Mixed Model

For the analysis of longitudinal data to take into account the correlation between measurements taken in the same experimental unit, the adjustment of regression models with the inclusion of random effects can be considered, and it's oftenly used in these kind of cases. The usual models are:

\begin{itemize}
  \item Linear Mixed Models;
  \item Generalized Linear Mixed Models;
  \item Non-Linear Mixed Models.
\end{itemize}

In this we will speak specifically about Linear Mixed Models (LMM) since is the most common model used in this kind of situation. So we'll use LMM to fit the mean profile of the subjects.

As usually done in Linear Models, the LMM is use to make the inference on the populacional mean of the populacion, but in the LMM is used the y conditioned in u, in other words E[Y|u]. For a LMM $X\beta$ represent the fixed effects, but is added a random effect represented by Zu, where just as X is the knew model matriz, and u the random variables used to define the condicional model, expressed as:

\begin{equation}
  E[Y|u] = X\beta + Zu + \varepsilon \label{eq}
\end{equation}

Where from the model \ref{eq} is usually assumed that $b_i \sim N_q(0,G)$ and $\varepsilon \sim N_{m_i}(0,R_i)$, where $m_i$ is the number of instants that the subject is measured.

\begin{table}[H]
\centering
\caption{Summary of the dimensions of each component}
\label{tab1}
\begin{tabular}{lc}
\hline
Componente & Dimensão          \\ \hline
y             & $N \times 1$   \\
X             & $N \times p$   \\
$\beta$       & $p \times 1$   \\
Z             & $N \times nq$  \\
b             & $nq \times 1$  \\
$\varepsilon$ & $N \times 1$   \\
$\Gamma$      & $nq \times nq$ \\
R             & $N \times N$   \\
$\Omega$      & $N \times N$   \\
$\theta$      & $t \times t$   \\ \hline
\end{tabular}
\end{table}

WHere in a more techinicall manner the modelo \ref{eq}, which $y = [ y_1^T, \cdots , y_n^T ] (N \times 1)$, with  $N = \sum_{i = 1}^n n_i$, have the fixed part and the random part, the parameter of the model can be write in a matter where $b \sim N_{nq}(0, \Gamma(\theta))$, where $\Gamma(\theta) = I_n \otimes G(\theta)$ is independent of $\varepsilon \sim N_N(0,R(\theta)), R(\theta) = \otimes_{i = 1}^n R_i(\theta)$, with give the final distribuition of y as $y \sim N_N(X\beta,\Omega(\theta))$, where $\Omega(\theta) = Z\Gamma(\theta)Z^T + R(\theta)$.

Which show us that the fixed effect affect only the mean of y, when the random affect affect the variance of y.

# Structure of the covariance

The greater part of the effort of fit a Mixed Linear Model is to choose the structure of the covariance, which greatly affect the goodness-of-fit of the fitted model.

Theorically speaking those structure can be used on $\Omega(\theta), R(\theta)$ and $G(\theta)$, but is usually used in the variance of y ($\Omega(\theta)$).

Some exemples of covariante structure, considering $n_i = 4$:

## Uniform structure
[$\theta = (\sigma^2,\tau)^T$]

\begin{center}
  $\begin{bmatrix}
   \sigma^2 + \tau & \tau & \tau & \tau \\ 
   \tau & \sigma^2 + \tau & \tau & \tau \\ 
   \tau & \tau & \sigma^2 + \tau & \tau \\ 
   \tau & \tau & \tau & \sigma^2 + \tau
  \end{bmatrix}$
\end{center}

## AR(1) structure
[$\theta = (\sigma^2, \phi)^T$]

\begin{center}
  $\begin{bmatrix}
   1      & \phi   & \phi^2 & \phi^3 \\ 
   \phi   & 1      & \phi   & \phi^2 \\ 
   \phi^2 & \phi   & 1      & \phi \\ 
   \phi^3 & \phi^2 & \phi   & 1
  \end{bmatrix}$
\end{center}

## ARMA(1,1) structure
[$\theta = (\sigma^2,\phi, \gamma)^T$]

\begin{center}
  $\begin{bmatrix}
   1            & \gamma     & \phi\gamma & \gamma\phi^2 \\ 
   \gamma       & 1          & \gamma     & \gamma\phi \\ 
   \gamma\phi   & \gamma     & 1          & \gamma \\ 
   \gamma\phi^2 & \gamma\phi & \gamma     & 1
  \end{bmatrix}$
\end{center}

## Antidependence structure of 1st order
[$\theta = (\sigma_1^2, \sigma_2^2, \sigma_3^2, \sigma_4^2, \rho_1, \rho_2, \rho_3, \rho_4)^T$]

\begin{center}
  $\begin{bmatrix}
   \sigma_1^2            & \sigma_1\sigma_2\rho_1     & \sigma_1\sigma_3\rho_1\rho_2 & \sigma_1\sigma_4\rho_1\rho_2\rho_3 \\ 
   \sigma_1\sigma_2\rho_1       & \sigma_2^2          & \sigma_2\sigma_3\rho_2     & \sigma_2\sigma_4\rho_2\rho_3 \\ 
   \sigma_1\sigma_3\rho_1\rho_2   & \sigma_2\sigma_3\rho_2     & \sigma_3^2          & \sigma_3\sigma_4\rho_3 \\ 
   \sigma_1\sigma_4\rho_1\rho_2\rho_3 & \sigma_2\sigma_4\rho_2\rho_3 & \sigma_3\sigma_4\rho_3     & \sigma_4^2
  \end{bmatrix}$
\end{center}

## Toeplitz structure
[$\theta = (\sigma^2, \sigma_1, \sigma_2, \sigma_3)^T$]

\begin{center}
  $\begin{bmatrix}
   \sigma^2 & \sigma_1 & \sigma_2 & \sigma_3 \\ 
   \sigma_1 & \sigma^2 & \sigma_1 & \sigma_2 \\ 
   \sigma_2 & \sigma_1 & \sigma^2 & \sigma_1 \\ 
   \sigma_3 & \sigma_2 & \sigma_1 & \sigma^2
  \end{bmatrix}$
\end{center}

## Hetorogenally uniform structure
[$\theta = (\sigma_1^2, \sigma_2^2, \sigma_3^2, \sigma_4^2, \rho)^T$]

\begin{center}
  $\begin{bmatrix}
   \sigma_1^2           & \sigma_1\sigma_2\rho & \sigma_1\sigma_3\rho & \sigma_1\sigma_4\rho \\ 
   \sigma_2\sigma_1\rho & \sigma_2^2           & \sigma_2\sigma_3\rho & \sigma_2\sigma_4\rho \\ 
   \sigma_3\sigma_1\rho & \sigma_3\sigma_2\rho & \sigma_3^2           & \sigma_3\sigma_4\rho \\ 
   \sigma_4\sigma_1\rho & \sigma_4\sigma_2\rho & \sigma_4\sigma_3\rho & \sigma_4^2
  \end{bmatrix}$
\end{center}

## Not structured
[$\theta = (\sigma_1^2, \sigma_2^2, \sigma_3^2, \sigma_4^2, \sigma_{12}, \sigma_{13}, \sigma_{14}, \sigma_{23}, \sigma_{24}, \sigma_{34})^T$]

\begin{center}
  $\begin{bmatrix}
   \sigma_1^2  & \sigma_{12} & \sigma_{13} & \sigma_{14} \\ 
   \sigma_{12} & \sigma_2^2  & \sigma_{23} & \sigma_{24} \\ 
   \sigma_{13} & \sigma_{23} & \sigma_3^2  & \sigma_{34} \\ 
   \sigma_{14} & \sigma_{24} & \sigma_{34} & \sigma_4^2
  \end{bmatrix}$
\end{center}

# Chiken diet Data

the `ChickWeight` available on r by using the code `data("ChickWeight")`, is a data that containg 578 row and 4 variable, which measure 50 different chickens on 12 different times where the model contains some datas which some missing value that are not  explicit on the data it self.

For exemple, the Chicken number 18 has only been measure on the time 0 and not on the subsequent time. The help (`help(data("ChickWeight"))`) of the database doesn't provite us the explanation/detail of why that occours.

In the present work, we will be discarting those cases where the data is not complete, as defined in the beginning, since is one of the assumptions of the model, but that problem can be solved by using a different mode, such as Generalized Linear Mixed Models, considering a distribuition capable of fitting data with "censor", or even by using an non-parametric analysis or Random Forest.

But since the presence of NA is only in 5 cases (8,15,16,18,44) was decided to drop the data for lack of good technical features. The absence of which observation can be seen on the table bellow.

```{r, results = 'asis', echo = F, warning = F, message = F}
tab1 <- table(
  ChickWeight$Chick,
  ChickWeight$Time
)
cn <- colnames(tab1)
rn <- rownames(tab1)
tab1 %<>%
  as.matrix.data.frame() %>%
  as_tibble()

tab1 %>% 
  set_colnames(cn) %>%
  summarise(
    across(where(is.numeric), 
           ~ ifelse(
             .x == 0, 'x', .x
           )
    )
  ) %>% 
  cbind(rn) %>% 
  dplyr::select(rn,everything()) %>%  
  rename(Chick = rn) %>% 
  mutate(
    Chick = Chick %>% as.character() %>% as.numeric()
  ) %>% 
  arrange(Chick) %>% 
  kable(format = "latex", booktabs = TRUE) %>%
  kable_styling(
    position = 'center',
    latex_options = 'HOLD_position'
  )
```

Now we'll give some descriptive analisys of the data to help us to get some help for the decision of the implentation of the random effects.

```{r}
data("ChickWeight")
ChickWeight %<>%
  filter(!Chick %in% c(8,15,16,18,44))

frango <- groupedData(
  weight~Time|Chick, outer = ~Diet, data = ChickWeight,
  order.groups = F,
  labels=list(x="tempo (semana)", y="Peso corporal (g)")
)

plot(frango, between = list(y = c(0, 0.5, 0)))
```

The first plot show us a different inclination for each chicken, when taken Weigth in relation with Time, which shown us a possible random effects of the the inclination of the line, but is not shown a possible random effect on the intercepto. By a closer observation on the same plot can be shown a possible quadratic effect, so in the model will be added on the model, and after de decision of the model, we will make a anova to see if that quadratic coef is significative in relation with the model without it.

```{r}
plot(frango, outer = T, key=FALSE) # key omite a legenda
```


By the second graph, it gives us a good visual effect a high variation of the mean weigth for each chicken in time for each Diet, what give us a good intuition that exist a random effect for this case.

```{r}
interaction.plot(frango$Time,frango$Diet,frango$weight,ylab="Peso (g)", xlab="Tempo (semana)")
```


For the last graph, is a good plot to show a possible difference on the effect for each Diet.

```{r}
mod1 <- lme(
  fixed = weight~Time+I(Time^2)+Diet+Time:Diet,
  random = ~1,
  data = frango,
  control = lmeControl(opt="optim")
)
mod2 <- lme(
  fixed = weight~Time+I(Time^2)+Diet+Time:Diet,
  random = ~ Diet,
  data = frango,
  control = lmeControl(opt="optim")
)
mod3 <- lme(
  fixed = weight~Time+I(Time^2)+Diet+Time:Diet,
  random = ~Time,
  data = frango,
  control = lmeControl(opt="optim")
)
mod4 <- lme(
  fixed = weight~Time+I(Time^2)+Diet+Time:Diet,
  random = ~Time + Diet,
  data = frango,
  control = lmeControl(opt="optim")
)
mod5 <- lme(
  fixed = weight~Time+I(Time^2)+Diet+Time:Diet,
  random = ~Time + Diet + Time:Diet,
  data = frango,
  control = lmeControl(opt="optim")
)
```

```{r}
tibble(
  Modelo = paste('Modelo',1:5),
  AIC = c(AIC(mod1),AIC(mod2),AIC(mod3),AIC(mod4),AIC(mod5)),
  BIC = c(BIC(mod1),BIC(mod2),BIC(mod3),BIC(mod4),BIC(mod5))
) %>% arrange(BIC,AIC)
```


```{r, results = 'asis'}
coef(mod3) %>%
  as_tibble() %>%
  kable(format = "latex", booktabs = TRUE)
```



## Changing the correlation matrix structure

```{r}
mod3_corAR1 <- lme(
  fixed = weight~Time+I(Time^2)+Diet+Time:Diet,
  random = ~Time+I(Time^2),
  data = frango,
  control = lmeControl(opt="optim"),
  correlation = corAR1()
)
mod3_corARMA <- lme(
  fixed = weight~Time+I(Time^2)+Diet+Time:Diet,
  random = ~Time+I(Time^2),
  data = frango,
  control = lmeControl(opt="optim"),
  correlation = corARMA(p = 0, q = 2)
)
mod3_corCAR1 <- lme(
  fixed = weight~Time+I(Time^2)+Diet+Time:Diet,
  random = ~Time+I(Time^2),
  data = frango,
  control = lmeControl(opt="optim"),
  correlation = corCAR1(form = ~Time)
)
mod3_corCompSymm <- lme(
  fixed = weight~Time+I(Time^2)+Diet+Time:Diet,
  random = ~Time+I(Time^2),
  data = frango,
  control = lmeControl(opt="optim"),
  correlation = corCompSymm()
)
mod3_corExp <- lme(
  fixed = weight~Time+I(Time^2)+Diet+Time:Diet,
  random = ~Time+I(Time^2),
  data = frango,
  control = lmeControl(opt="optim"),
  correlation = corExp(form = ~Time)
)
mod3_corGaus <- lme(
  fixed = weight~Time+I(Time^2)+Diet+Time:Diet,
  random = ~Time+I(Time^2),
  data = frango,
  control = lmeControl(opt="optim"),
  correlation = corGaus(form = ~Time)
)
mod3_corLin <- lme(
  fixed = weight~Time+I(Time^2)+Diet+Time:Diet,
  random = ~Time+I(Time^2),
  data = frango,
  control = lmeControl(opt="optim"),
  correlation = corLin(form = ~Time)
)
mod3_corRatio <- lme(
  fixed = weight~Time+I(Time^2)+Diet+Time:Diet,
  random = ~Time+I(Time^2),
  data = frango,
  control = lmeControl(opt="optim"),
  correlation = corRatio(form = ~Time)
)
mod3_corSpher <- lme(
  fixed = weight~Time+I(Time^2)+Diet+Time:Diet,
  random = ~Time+I(Time^2),
  data = frango,
  control = lmeControl(opt="optim"),
  correlation = corSpher(form = ~ Time)
)
mod3_corSymm <- lme(
  fixed = weight~Time+I(Time^2)+Diet+Time:Diet,
  random = ~Time+I(Time^2),
  data = frango,
  control = lmeControl(opt="optim"),
  correlation = corSymm(form = ~ 1|Chick, fixed = T)
)
```

```{r}
lme(
  fixed = weight~Time+I(Time^2)+Diet+Time:Diet,
  random = ~Time+I(Time^2),
  data = frango,
  control = lmeControl(opt="optim")
) %>% AIC()
```


```{r}
tibble(
  modelo = c(
    'mod3_corAR1','mod3_corARMA02','mod3_corCAR1',
    'mod3_corCompSymm','mod3_corExp','mod3_corGaus',
    'mod3_corLin','mod3_corRatio','mod3_corSpher',
    'mod3_corSymm'
  ),
  AIC = c(
    AIC(mod3_corAR1),AIC(mod3_corARMA),AIC(mod3_corCAR1),
    AIC(mod3_corCompSymm),AIC(mod3_corExp),AIC(mod3_corGaus),
    AIC(mod3_corLin),AIC(mod3_corRatio),AIC(mod3_corSpher),
    AIC(mod3_corSymm)
  ),
  BIC = c(
    BIC(mod3_corAR1),BIC(mod3_corARMA),BIC(mod3_corCAR1),
    BIC(mod3_corCompSymm),BIC(mod3_corExp),BIC(mod3_corGaus),
    BIC(mod3_corLin),BIC(mod3_corRatio),BIC(mod3_corSpher),
    BIC(mod3_corSymm)
  )
) %>% arrange(AIC,BIC)
```

```{r}

```

